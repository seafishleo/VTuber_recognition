{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNotSsOTYUNK0MSHyzJRWTL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ww9RybNTV454"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import time\n","import model\n","from tensorflow import gfile\n","from tensorflow import logging\n","from datetime import datetime\n","from PIL import Image, ImageDraw, ImageFont\n","from operator import itemgetter\n","\n","BATCH_SIZE = 100\n","NUM_EPOCHS = 1\n","LOGDIR = '/content/drive/MyDrive/VTuber_recognition/logdir/'\n","\n","IMAGE_WIDTH = 128\n","IMAGE_HEIGHT = 128\n","IMAGE_CHANNE = 3\n","TARGET_SIZE = 5\n","\n","INPUT_TEST_TFRECORD = '/content/drive/MyDrive/VTuber_recognition/test_tfrecords/*.tfrecords'\n","\n","def read_and_decode(filename_queue):\n","  reader = tf.TFRecordReader()\n","  key, value = reader.read(filename_queue)\n","\n","  features = tf.parse_single_example(\n","      value,\n","      features={'label': tf.FixedLenFeature([], tf.int64, default_value=0),\n","                'image': tf.FixedLenFeature([], tf.string, default_value=\"\")\n","      })\n","\n","  label = tf.cast(features['label'], tf.int32)\n","  label = tf.one_hot(label, TARGET_SIZE)\n","\n","  image = tf.decode_raw(features['image'], tf.uint8)\n","  image = tf.cast(image, tf.float32)\n","  image = image / 255  # 0~1\n","  image = tf.reshape(image, [IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_CHANNE])\n","\n","  return image, label\n","\n","\n","def inputs(batch_size, num_epochs, input_tfrecord):\n","  if not num_epochs:\n","      num_epochs = None\n","\n","  with tf.name_scope('input'):\n","\n","      files = gfile.Glob(input_tfrecord)\n","      files = sorted(files)\n","\n","      print(\"files num : \", len(files))\n","\n","      if not files:\n","          raise IOError(\"Unable to find training files. data_pattern='\" +\n","                        input_tfrecord + \"'.\")\n","      logging.info(\"Number of training files: %s.\", str(len(files)))\n","\n","      filename_queue = tf.train.string_input_producer(files, num_epochs=num_epochs, shuffle=False)\n","\n","      image, label = read_and_decode(filename_queue)\n","\n","      print(\"image     :\", image.shape)\n","      print(\"label      :\", label.shape)\n","\n","      image_batch, label_batch = tf.train.shuffle_batch(\n","          [image, label],\n","          batch_size=batch_size,\n","          num_threads=10,\n","          capacity=10000 + 15 * batch_size,\n","          min_after_dequeue=10000,\n","          allow_smaller_final_batch=False # True --> error ...\n","          )\n","\n","      return image_batch, label_batch\n","\n","def save_result(image_batch_step, softmax_step, step):\n","  label = ['Korone', 'Okayu', 'Mio', 'Subaru', 'Fubuki']\n","\n","  for i, (image, softmax) in enumerate(zip(image_batch_step, softmax_step)):\n","      label_tuples = []\n","      for (l, s) in zip(label, softmax):\n","          label_tuples.append((l, s))\n","      label_tuples = sorted(label_tuples, key=itemgetter(1), reverse=True)\n","\n","      image = image * 255\n","      image = Image.fromarray(np.uint8(image))\n","      draw = ImageDraw.Draw(image)\n","      font = ImageFont.truetype(\"/home/user/.fonts/Ubuntu-L.ttf\", 10)\n","\n","      for (j, r) in enumerate(label_tuples):\n","          l, s = r\n","          draw.text((10, j * 10), l + ' : {:.3f}'.format(s), fill=(255, 0, 0), font=font)\n","\n","      image.save('/content/drive/MyDrive/VTuber_recognition/RESULT/' + str(step) + '-' + str(i) + '.jpg')\n","\n","if __name__ == \"__main__\":\n","\n","  with tf.Graph().as_default():\n","\n","    print('Reading batches...')\n","    image_batch, label_batch = inputs(batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS, input_tfrecord=INPUT_TEST_TFRECORD)\n","\n","    print('build models...')\n","    y_conv = model.inference(image_batch, BATCH_SIZE, is_training=False)\n","    softmax = tf.nn.softmax(y_conv)\n","\n","    global_step = tf.Variable(0, trainable=False)\n","\n","    # calculate accuracy\n","    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(label_batch, 1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","    config = tf.ConfigProto()\n","    config.gpu_options.allow_growth = True\n","\n","    sv = tf.train.Supervisor(logdir=LOGDIR, global_step=global_step)\n","\n","    with sv.managed_session(config=config) as sess:\n","      print('start loop...' + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","\n","      try:\n","      step = 0\n","      accu_all = []\n","      while not sv.should_stop():\n","          start_time = time.time()\n","\n","          accu_step, softmax_step, image_batch_step, g_step \\\n","                  = sess.run([accuracy, softmax, image_batch, global_step])\n","          accu_all.append(accu_step)\n","          print(softmax_step[:10])\n","          save_result(image_batch_step, softmax_step, step)\n","\n","          duration = time.time() - start_time\n","\n","          print('Step test %04d: accu = %07.4f (%02.3f sec)' %(step,\n","                                                                accu_step,\n","                                                                duration))\n","          step += 1\n","\n","      except tf.errors.OutOfRangeError:\n","        print('Done testing for %d epochs, %d steps.' %\n","              (NUM_EPOCHS, step))\n","\n","      accu_all_mean = np.array(accu_all).mean()\n","      print(\"accu_all_mean : \", accu_all_mean)\n","\n","      sv.Stop()\n","\n","    print('End loop...' + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"]}]}